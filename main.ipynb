{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7523149",
   "metadata": {},
   "source": [
    "# CYBERML Project 2025-2026\n",
    "## IoT Intrusion Detection and Attack Analysis\n",
    "\n",
    "### Objectives:\n",
    "1. **Classification and Anomaly Detection** for tracking attacks\n",
    "2. **Adversarial Attacks** against classification (bonus)\n",
    "\n",
    "### Dataset: CIC IoT-DIAD 2024\n",
    "Source: https://www.unb.ca/cic/datasets/iot-diad-2024.html\n",
    "\n",
    "**Note:** This notebook uses stratified sampling to handle the large 50GB dataset efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07ae1ad",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c983908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install pandas numpy scikit-learn matplotlib seaborn imbalanced-learn xgboost lightgbm plotly nbformat tensorflow\n",
    "\n",
    "# (UV IS PREFFERED, DON'T USE THIS &v&)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4fbd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download http://cicresearch.ca/IOTDataset/CIC%20IoT-IDAD%20Dataset%202024/Dataset/ into the local data/ directory\n",
    "# Download the full directory recursively using wget under data/\n",
    "!wget -r -np -nH --cut-dirs=3 -R \"index.html*\" -P data/ \"http://cicresearch.ca/IOTDataset/CIC%20IoT-IDAD%20Dataset%202024/Dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9795d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "import gc\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set matplotlib style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Unsupervised Learning (Anomaly Detection)\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "# Supervised Learning (Classification)\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, accuracy_score,\n",
    "    precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    average_precision_score, balanced_accuracy_score, matthews_corrcoef,\n",
    "    precision_recall_curve, roc_curve, ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# Imbalanced data handling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3d4485",
   "metadata": {},
   "source": [
    "## 2. Memory-Efficient Data Loading with Stratified Sampling\n",
    "\n",
    "Since the dataset is ~50GB, we use stratified sampling to:\n",
    "- Sample a fixed number of rows from each attack category\n",
    "- Maintain class distribution representation\n",
    "- Keep memory usage manageable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a34683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for sampling\n",
    "DATA_ROOT = \"data/Anomaly Detection - Flow Based features/\"\n",
    "SAMPLES_PER_CATEGORY = 10000  # Adjust based on available memory\n",
    "CHUNK_SIZE = 50000  # Read CSV in chunks\n",
    "\n",
    "# Define attack categories and their folder mappings\n",
    "ATTACK_CATEGORIES = {\n",
    "    'Benign': 'Benign',\n",
    "    'BruteForce': 'BruteForce',\n",
    "    'DDoS': 'DDoS',\n",
    "    'DoS': 'DoS',\n",
    "    'Mirai': 'Mirai',\n",
    "    'Recon': 'Recon',\n",
    "    'Spoofing': 'Spoofing',\n",
    "    'Web-Based': 'Web-Based'\n",
    "}\n",
    "\n",
    "print(f\"Sampling {SAMPLES_PER_CATEGORY} rows per category\")\n",
    "print(f\"Categories: {list(ATTACK_CATEGORIES.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5f1a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_files_for_category(category_path):\n",
    "    \"\"\"Recursively find all CSV files in a category folder.\"\"\"\n",
    "    csv_files = glob.glob(os.path.join(category_path, \"**/*.csv\"), recursive=True)\n",
    "    return csv_files\n",
    "\n",
    "def sample_from_csv(file_path, n_samples, chunk_size=CHUNK_SIZE):\n",
    "    \"\"\"Sample n rows from a CSV file using reservoir sampling approach.\"\"\"\n",
    "    # First, count total rows (fast scan)\n",
    "    total_rows = sum(1 for _ in open(file_path, 'r')) - 1  # -1 for header\n",
    "    \n",
    "    if total_rows <= 0:\n",
    "        return None\n",
    "    \n",
    "    if total_rows <= n_samples:\n",
    "        # File is small enough, read entirely\n",
    "        try:\n",
    "            return pd.read_csv(file_path, low_memory=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # Random sample of row indices to keep\n",
    "    skip_idx = set(range(1, total_rows + 1)) - set(np.random.choice(range(1, total_rows + 1), n_samples, replace=False))\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(file_path, skiprows=skip_idx, low_memory=False)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error sampling {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_category_sample(category_name, category_folder, n_samples):\n",
    "    \"\"\"Load a stratified sample from all files in a category.\"\"\"\n",
    "    category_path = os.path.join(DATA_ROOT, category_folder)\n",
    "    csv_files = get_csv_files_for_category(category_path)\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(f\"No CSV files found in {category_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\n{category_name}: Found {len(csv_files)} CSV files\")\n",
    "    \n",
    "    # Distribute samples across files\n",
    "    samples_per_file = max(1, n_samples // len(csv_files))\n",
    "    \n",
    "    dfs = []\n",
    "    total_sampled = 0\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        if total_sampled >= n_samples:\n",
    "            break\n",
    "            \n",
    "        remaining = n_samples - total_sampled\n",
    "        to_sample = min(samples_per_file, remaining)\n",
    "        \n",
    "        df_sample = sample_from_csv(csv_file, to_sample)\n",
    "        if df_sample is not None and len(df_sample) > 0:\n",
    "            dfs.append(df_sample)\n",
    "            total_sampled += len(df_sample)\n",
    "            print(f\"  - {os.path.basename(csv_file)}: {len(df_sample)} samples\")\n",
    "    \n",
    "    if not dfs:\n",
    "        return None\n",
    "    \n",
    "    result = pd.concat(dfs, ignore_index=True)\n",
    "    result['Label'] = category_name\n",
    "    \n",
    "    # Clean up\n",
    "    del dfs\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"  Total samples for {category_name}: {len(result)}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d867cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stratified samples from each category\n",
    "print(\"Loading stratified samples from each attack category...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_samples = []\n",
    "\n",
    "for category_name, category_folder in ATTACK_CATEGORIES.items():\n",
    "    df_category = load_category_sample(category_name, category_folder, SAMPLES_PER_CATEGORY)\n",
    "    if df_category is not None:\n",
    "        all_samples.append(df_category)\n",
    "    gc.collect()\n",
    "\n",
    "# Combine all samples\n",
    "df = pd.concat(all_samples, ignore_index=True)\n",
    "del all_samples\n",
    "gc.collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Total dataset shape: {df.shape}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1939c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Number of samples: {len(df)}\")\n",
    "print(f\"Number of features: {len(df.columns)}\")\n",
    "print(f\"\\nColumn names:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d470c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93d774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and missing values\n",
    "print(\"Data Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nMissing Values:\")\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "missing_df = pd.DataFrame({'Missing Count': missing, 'Percentage': missing_pct})\n",
    "print(missing_df[missing_df['Missing Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd373bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b61ddf",
   "metadata": {},
   "source": [
    "## 3. Dataset Characterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de60d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label distribution\n",
    "label_col = 'Label'\n",
    "print(f\"Label column: {label_col}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "label_counts = df[label_col].value_counts()\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c97837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize label distribution\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(label_counts)))\n",
    "bars = ax.bar(label_counts.index, label_counts.values, color=colors)\n",
    "ax.set_xlabel('Attack Type')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Distribution of Attack Types (Sampled Dataset)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "for bar, count in zip(bars, label_counts.values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 100, f'{count}', ha='center', va='bottom', fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6bbacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart for label distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(label_counts)))\n",
    "wedges, texts, autotexts = ax.pie(\n",
    "    label_counts.values, \n",
    "    labels=label_counts.index, \n",
    "    autopct='%1.1f%%',\n",
    "    colors=colors,\n",
    "    pctdistance=0.85,\n",
    "    explode=[0.02] * len(label_counts)\n",
    ")\n",
    "centre_circle = plt.Circle((0, 0), 0.50, fc='white')\n",
    "ax.add_patch(centre_circle)\n",
    "ax.set_title('Proportion of Attack Types')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8105cc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary label for anomaly detection (Benign vs Attack)\n",
    "df['is_attack'] = (df[label_col] != 'Benign').astype(int)\n",
    "\n",
    "print(\"Binary Classification Distribution:\")\n",
    "print(df['is_attack'].value_counts())\n",
    "print(f\"\\nAttack ratio: {df['is_attack'].mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b913935c",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f5c08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep a copy of labels\n",
    "y_multiclass = df[label_col].copy()\n",
    "y_binary = df['is_attack'].copy()\n",
    "\n",
    "# Drop label columns from features\n",
    "df_features = df.drop(columns=[label_col, 'is_attack'])\n",
    "\n",
    "print(f\"Features shape: {df_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcd0c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle non-numeric columns\n",
    "non_numeric_cols = df_features.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Non-numeric columns: {non_numeric_cols}\")\n",
    "\n",
    "# Drop IP addresses and similar identifier columns\n",
    "cols_to_drop = [col for col in non_numeric_cols if any(x in col.lower() for x in ['ip', 'address', 'id', 'time', 'stamp'])]\n",
    "df_features = df_features.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "# Label encode remaining categorical columns\n",
    "remaining_object_cols = df_features.select_dtypes(include=['object']).columns.tolist()\n",
    "le = LabelEncoder()\n",
    "for col in remaining_object_cols:\n",
    "    df_features[col] = le.fit_transform(df_features[col].astype(str))\n",
    "\n",
    "print(f\"Features shape after encoding: {df_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484e63bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle infinite values and fill missing values\n",
    "df_features = df_features.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Fill missing values with median\n",
    "for col in df_features.columns:\n",
    "    if df_features[col].isnull().any():\n",
    "        median_val = df_features[col].median()\n",
    "        df_features[col] = df_features[col].fillna(median_val if pd.notna(median_val) else 0)\n",
    "\n",
    "# Remove constant columns (variance = 0)\n",
    "constant_cols = df_features.columns[df_features.nunique() <= 1].tolist()\n",
    "df_features = df_features.drop(columns=constant_cols)\n",
    "print(f\"Removed {len(constant_cols)} constant columns\")\n",
    "print(f\"Final features shape: {df_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e286934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature correlation analysis (sample for visualization)\n",
    "plt.figure(figsize=(16, 14))\n",
    "sample_cols = df_features.columns[:min(30, len(df_features.columns))]\n",
    "corr_matrix = df_features[sample_cols].corr()\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm', center=0, annot=False)\n",
    "plt.title('Feature Correlation Matrix (First 30 Features)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15a3919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode multiclass labels\n",
    "le_multiclass = LabelEncoder()\n",
    "y_multiclass_encoded = le_multiclass.fit_transform(y_multiclass)\n",
    "class_names = le_multiclass.classes_\n",
    "print(f\"Classes: {class_names}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62718394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for training and testing\n",
    "X = df_features.values\n",
    "y = y_binary.values  # Binary classification\n",
    "y_multi = y_multiclass_encoded  # Multiclass classification\n",
    "\n",
    "# Train-test split (binary)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# Train-test split (multiclass)\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(\n",
    "    X, y_multi, test_size=0.2, random_state=RANDOM_STATE, stratify=y_multi\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473e61e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_multi_scaled = scaler.fit_transform(X_train_multi)\n",
    "X_test_multi_scaled = scaler.transform(X_test_multi)\n",
    "\n",
    "print(\"Features scaled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43240faa",
   "metadata": {},
   "source": [
    "## 5. Unsupervised Learning - Anomaly Detection\n",
    "\n",
    "We benchmark 3 complementary unsupervised algorithms:\n",
    "1. **Isolation Forest** - Tree-based anomaly detection\n",
    "2. **Local Outlier Factor (LOF)** - Density-based anomaly detection\n",
    "3. **One-Class SVM** - Support vector-based anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62afb621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_anomaly_detector(y_true, y_pred, model_name):\n",
    "    \"\"\"Evaluate anomaly detection model and return metrics.\"\"\"\n",
    "    # Convert predictions: -1 (anomaly) -> 1 (attack), 1 (normal) -> 0\n",
    "    y_pred_binary = np.where(y_pred == -1, 1, 0)\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred_binary)\n",
    "    precision = precision_score(y_true, y_pred_binary, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred_binary, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred_binary, zero_division=0)\n",
    "    balanced_acc = balanced_accuracy_score(y_true, y_pred_binary)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred_binary)\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
    "    print(f\"Matthews Correlation Coefficient: {mcc:.4f}\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Benign', 'Attack'])\n",
    "    disp.plot(ax=ax, cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'Balanced Accuracy': balanced_acc,\n",
    "        'MCC': mcc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c9f8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate contamination rate (proportion of attacks)\n",
    "contamination_rate = y_train.mean()\n",
    "print(f\"Contamination rate (attack ratio): {contamination_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ad2194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Isolation Forest\n",
    "print(\"Training Isolation Forest...\")\n",
    "iso_forest = IsolationForest(\n",
    "    n_estimators=100,\n",
    "    contamination=\"auto\",\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "iso_forest.fit(X_train_scaled)\n",
    "y_pred_iso = iso_forest.predict(X_test_scaled)\n",
    "iso_results = evaluate_anomaly_detector(y_test, y_pred_iso, \"Isolation Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b46e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Local Outlier Factor\n",
    "print(\"Training Local Outlier Factor...\")\n",
    "lof = LocalOutlierFactor(\n",
    "    n_neighbors=20,\n",
    "    contamination=\"auto\",\n",
    "    novelty=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "lof.fit(X_train_scaled)\n",
    "y_pred_lof = lof.predict(X_test_scaled)\n",
    "lof_results = evaluate_anomaly_detector(y_test, y_pred_lof, \"Local Outlier Factor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be912ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. One-Class SVM (using a subsample due to computational complexity)\n",
    "print(\"Training One-Class SVM...\")\n",
    "# Subsample for OCSVM (it's O(nÂ²) complexity)\n",
    "OCSVM_MAX_SAMPLES = 10000\n",
    "if len(X_train_scaled) > OCSVM_MAX_SAMPLES:\n",
    "    ocsvm_idx = np.random.choice(len(X_train_scaled), OCSVM_MAX_SAMPLES, replace=False)\n",
    "    X_train_ocsvm = X_train_scaled[ocsvm_idx]\n",
    "else:\n",
    "    X_train_ocsvm = X_train_scaled\n",
    "\n",
    "ocsvm = OneClassSVM(\n",
    "    kernel='rbf',\n",
    "    gamma='scale',\n",
    "    nu=min(contamination_rate, 0.5)  # nu must be <= 0.5\n",
    ")\n",
    "ocsvm.fit(X_train_ocsvm)\n",
    "y_pred_ocsvm = ocsvm.predict(X_test_scaled)\n",
    "ocsvm_results = evaluate_anomaly_detector(y_test, y_pred_ocsvm, \"One-Class SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52266cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of Anomaly Detection Results\n",
    "anomaly_results_df = pd.DataFrame([iso_results, lof_results, ocsvm_results])\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANOMALY DETECTION BENCHMARK SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(anomaly_results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebb7866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize anomaly detection results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "models = anomaly_results_df['Model'].tolist()\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "# Precision & Recall\n",
    "axes[0].bar(x - width/2, anomaly_results_df['Precision'], width, label='Precision', color='steelblue')\n",
    "axes[0].bar(x + width/2, anomaly_results_df['Recall'], width, label='Recall', color='darkorange')\n",
    "axes[0].set_xlabel('Model')\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].set_title('Precision & Recall')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(models, rotation=15, ha='right')\n",
    "axes[0].legend()\n",
    "axes[0].set_ylim(0, 1)\n",
    "\n",
    "# Balanced Accuracy & MCC\n",
    "axes[1].bar(x - width/2, anomaly_results_df['Balanced Accuracy'], width, label='Balanced Accuracy', color='seagreen')\n",
    "axes[1].bar(x + width/2, anomaly_results_df['MCC'], width, label='MCC', color='crimson')\n",
    "axes[1].set_xlabel('Model')\n",
    "axes[1].set_ylabel('Score')\n",
    "axes[1].set_title('Balanced Accuracy & MCC')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(models, rotation=15, ha='right')\n",
    "axes[1].legend()\n",
    "axes[1].set_ylim(0, 1)\n",
    "\n",
    "plt.suptitle('Anomaly Detection Performance Comparison', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392295e2",
   "metadata": {},
   "source": [
    "## 6. Supervised Learning - Classification\n",
    "\n",
    "We benchmark 3 complementary classification algorithms:\n",
    "1. **Random Forest** - Ensemble tree-based classifier\n",
    "2. **XGBoost** - Gradient boosting classifier\n",
    "3. **LightGBM** - Light gradient boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d31acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(model, X_train, X_test, y_train, y_test, model_name, class_names=None):\n",
    "    \"\"\"Train and evaluate a classifier with comprehensive metrics.\"\"\"\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Probabilities for AUPRC\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_prob = model.predict_proba(X_test)\n",
    "        try:\n",
    "            from sklearn.preprocessing import label_binarize\n",
    "            y_test_bin = label_binarize(y_test, classes=range(len(class_names)))\n",
    "            auprc = average_precision_score(y_test_bin, y_prob, average='weighted')\n",
    "        except:\n",
    "            auprc = 0.0\n",
    "    else:\n",
    "        auprc = 0.0\n",
    "    \n",
    "    # Metrics\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Precision (weighted): {precision:.4f}\")\n",
    "    print(f\"Recall (weighted): {recall:.4f}\")\n",
    "    print(f\"AUPRC (weighted): {auprc:.4f}\")\n",
    "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
    "    print(f\"Matthews Correlation Coefficient: {mcc:.4f}\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(ax=ax, cmap='Blues', xticks_rotation=45)\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'AUPRC': auprc,\n",
    "        'Balanced Accuracy': balanced_acc,\n",
    "        'MCC': mcc\n",
    "    }, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a1fd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Random Forest Classifier\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "rf_results, rf_model = evaluate_classifier(\n",
    "    rf, X_train_multi_scaled, X_test_multi_scaled, y_train_multi, y_test_multi,\n",
    "    \"Random Forest\", class_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82e2582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. XGBoost Classifier\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.1,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='mlogloss',\n",
    "    verbosity=0\n",
    ")\n",
    "xgb_results, xgb_model = evaluate_classifier(\n",
    "    xgb, X_train_multi_scaled, X_test_multi_scaled, y_train_multi, y_test_multi,\n",
    "    \"XGBoost\", class_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b7090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. LightGBM Classifier\n",
    "lgbm = LGBMClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.1,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    class_weight='balanced',\n",
    "    verbose=-1\n",
    ")\n",
    "lgbm_results, lgbm_model = evaluate_classifier(\n",
    "    lgbm, X_train_multi_scaled, X_test_multi_scaled, y_train_multi, y_test_multi,\n",
    "    \"LightGBM\", class_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112581a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of Classification Results\n",
    "classification_results_df = pd.DataFrame([rf_results, xgb_results, lgbm_results])\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLASSIFICATION BENCHMARK SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(classification_results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1b1b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize classification results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "models = classification_results_df['Model'].tolist()\n",
    "x = np.arange(len(models))\n",
    "width = 0.25\n",
    "\n",
    "# Precision, Recall & AUPRC\n",
    "axes[0].bar(x - width, classification_results_df['Precision'], width, label='Precision', color='steelblue')\n",
    "axes[0].bar(x, classification_results_df['Recall'], width, label='Recall', color='darkorange')\n",
    "axes[0].bar(x + width, classification_results_df['AUPRC'], width, label='AUPRC', color='forestgreen')\n",
    "axes[0].set_xlabel('Model')\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].set_title('Precision, Recall & AUPRC')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(models, rotation=15, ha='right')\n",
    "axes[0].legend()\n",
    "axes[0].set_ylim(0, 1)\n",
    "\n",
    "# Balanced Accuracy & MCC\n",
    "axes[1].bar(x - width/2, classification_results_df['Balanced Accuracy'], width, label='Balanced Accuracy', color='seagreen')\n",
    "axes[1].bar(x + width/2, classification_results_df['MCC'], width, label='MCC', color='crimson')\n",
    "axes[1].set_xlabel('Model')\n",
    "axes[1].set_ylabel('Score')\n",
    "axes[1].set_title('Balanced Accuracy & MCC')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(models, rotation=15, ha='right')\n",
    "axes[1].legend()\n",
    "axes[1].set_ylim(0, 1)\n",
    "\n",
    "plt.suptitle('Classification Performance Comparison', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58cbb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Analysis\n",
    "feature_names = df_features.columns.tolist()\n",
    "\n",
    "# Random Forest Feature Importance\n",
    "rf_importance = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=True).tail(20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.barh(rf_importance['Feature'], rf_importance['Importance'], color='steelblue')\n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_ylabel('Feature')\n",
    "ax.set_title('Top 20 Feature Importances (Random Forest)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58d77bf",
   "metadata": {},
   "source": [
    "## 7. Adversarial Attacks (Bonus - Objective 2)\n",
    "\n",
    "We implement adversarial attacks against the classification models:\n",
    "1. **FGSM (Fast Gradient Sign Method)** - White-box attack\n",
    "2. **PGD (Projected Gradient Descent)** - Iterative white-box attack\n",
    "3. **Noise-based perturbation** - Simple black-box attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5941ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow for neural network\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Build a neural network for adversarial attack demonstration\n",
    "def build_nn_model(input_shape, num_classes):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(input_shape,)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "print(\"Neural network model builder ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46862cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train neural network\n",
    "num_classes = len(class_names)\n",
    "input_shape = X_train_multi_scaled.shape[1]\n",
    "\n",
    "nn_model = build_nn_model(input_shape, num_classes)\n",
    "\n",
    "# Train with early stopping\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "print(\"Training Neural Network...\")\n",
    "history = nn_model.fit(\n",
    "    X_train_multi_scaled, y_train_multi,\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07c37a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate baseline model performance\n",
    "baseline_loss, baseline_acc = nn_model.evaluate(X_test_multi_scaled, y_test_multi, verbose=0)\n",
    "print(f\"Baseline Neural Network Accuracy: {baseline_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f615d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM Attack Implementation\n",
    "def fgsm_attack(model, x, y, epsilon=0.1):\n",
    "    \"\"\"Fast Gradient Sign Method attack.\"\"\"\n",
    "    x_tensor = tf.convert_to_tensor(x, dtype=tf.float32)\n",
    "    y_tensor = tf.convert_to_tensor(y, dtype=tf.int32)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(x_tensor)\n",
    "        predictions = model(x_tensor)\n",
    "        loss = keras.losses.sparse_categorical_crossentropy(y_tensor, predictions)\n",
    "    \n",
    "    gradients = tape.gradient(loss, x_tensor)\n",
    "    signed_grad = tf.sign(gradients)\n",
    "    x_adv = x_tensor + epsilon * signed_grad\n",
    "    return x_adv.numpy()\n",
    "\n",
    "# PGD Attack Implementation\n",
    "def pgd_attack(model, x, y, epsilon=0.1, alpha=0.01, num_iter=10):\n",
    "    \"\"\"Projected Gradient Descent attack.\"\"\"\n",
    "    x_adv = tf.identity(tf.convert_to_tensor(x, dtype=tf.float32))\n",
    "    x_original = tf.convert_to_tensor(x, dtype=tf.float32)\n",
    "    y_tensor = tf.convert_to_tensor(y, dtype=tf.int32)\n",
    "    \n",
    "    for _ in range(num_iter):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(x_adv)\n",
    "            predictions = model(x_adv)\n",
    "            loss = keras.losses.sparse_categorical_crossentropy(y_tensor, predictions)\n",
    "        \n",
    "        gradients = tape.gradient(loss, x_adv)\n",
    "        x_adv = x_adv + alpha * tf.sign(gradients)\n",
    "        perturbation = tf.clip_by_value(x_adv - x_original, -epsilon, epsilon)\n",
    "        x_adv = x_original + perturbation\n",
    "    \n",
    "    return x_adv.numpy()\n",
    "\n",
    "# Noise-based attack (Black-box)\n",
    "def noise_attack(x, epsilon=0.1):\n",
    "    \"\"\"Simple random noise perturbation attack.\"\"\"\n",
    "    noise = np.random.uniform(-epsilon, epsilon, x.shape)\n",
    "    return x + noise\n",
    "\n",
    "print(\"Attack functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09e9912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate adversarial attacks with different epsilon values\n",
    "epsilons = [0.01, 0.05, 0.1, 0.2, 0.3]\n",
    "adversarial_results = []\n",
    "\n",
    "# Use a subset for faster evaluation\n",
    "ADV_SAMPLES = min(2000, len(X_test_multi_scaled))\n",
    "X_adv_test = X_test_multi_scaled[:ADV_SAMPLES]\n",
    "y_adv_test = y_test_multi[:ADV_SAMPLES]\n",
    "\n",
    "print(\"Evaluating adversarial attacks...\")\n",
    "print(f\"Using {ADV_SAMPLES} test samples\")\n",
    "\n",
    "for eps in epsilons:\n",
    "    print(f\"\\nEpsilon = {eps}\")\n",
    "    \n",
    "    # FGSM\n",
    "    X_fgsm = fgsm_attack(nn_model, X_adv_test, y_adv_test, epsilon=eps)\n",
    "    _, fgsm_acc = nn_model.evaluate(X_fgsm, y_adv_test, verbose=0)\n",
    "    \n",
    "    # PGD\n",
    "    X_pgd = pgd_attack(nn_model, X_adv_test, y_adv_test, epsilon=eps)\n",
    "    _, pgd_acc = nn_model.evaluate(X_pgd, y_adv_test, verbose=0)\n",
    "    \n",
    "    # Noise\n",
    "    X_noise = noise_attack(X_adv_test, epsilon=eps)\n",
    "    _, noise_acc = nn_model.evaluate(X_noise, y_adv_test, verbose=0)\n",
    "    \n",
    "    adversarial_results.append({\n",
    "        'Epsilon': eps,\n",
    "        'Baseline': baseline_acc,\n",
    "        'FGSM': fgsm_acc,\n",
    "        'PGD': pgd_acc,\n",
    "        'Noise': noise_acc\n",
    "    })\n",
    "    \n",
    "    print(f\"  FGSM Accuracy: {fgsm_acc:.4f} (drop: {(baseline_acc - fgsm_acc)*100:.2f}%)\")\n",
    "    print(f\"  PGD Accuracy: {pgd_acc:.4f} (drop: {(baseline_acc - pgd_acc)*100:.2f}%)\")\n",
    "    print(f\"  Noise Accuracy: {noise_acc:.4f} (drop: {(baseline_acc - noise_acc)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f63a345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize adversarial attack results\n",
    "adv_df = pd.DataFrame(adversarial_results)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(adv_df['Epsilon'], adv_df['Baseline'], 'k--', marker='o', label='Baseline', linewidth=2)\n",
    "ax.plot(adv_df['Epsilon'], adv_df['FGSM'], 'r-', marker='s', label='FGSM Attack', linewidth=2)\n",
    "ax.plot(adv_df['Epsilon'], adv_df['PGD'], 'b-', marker='^', label='PGD Attack', linewidth=2)\n",
    "ax.plot(adv_df['Epsilon'], adv_df['Noise'], 'g-', marker='d', label='Noise Attack', linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Epsilon (Perturbation Strength)')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Model Accuracy Under Adversarial Attacks')\n",
    "ax.set_ylim(0, 1)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc49272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table of adversarial attack results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ADVERSARIAL ATTACKS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(adv_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6563fd7",
   "metadata": {},
   "source": [
    "## 8. Conclusions and Security Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45c3b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary\n",
    "print(\"=\"*70)\n",
    "print(\"CYBERML PROJECT - FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. DATASET CHARACTERIZATION\")\n",
    "print(f\"   - Sampled dataset size: {len(df)}\")\n",
    "print(f\"   - Number of features: {len(df_features.columns)}\")\n",
    "print(f\"   - Number of attack classes: {len(class_names)}\")\n",
    "print(f\"   - Classes: {list(class_names)}\")\n",
    "print(f\"   - Attack ratio in sample: {y_binary.mean()*100:.2f}%\")\n",
    "\n",
    "print(\"\\n2. ANOMALY DETECTION RESULTS\")\n",
    "best_anomaly = anomaly_results_df.loc[anomaly_results_df['MCC'].idxmax()]\n",
    "print(f\"   Best Model: {best_anomaly['Model']}\")\n",
    "print(f\"   - MCC: {best_anomaly['MCC']:.4f}\")\n",
    "print(f\"   - Balanced Accuracy: {best_anomaly['Balanced Accuracy']:.4f}\")\n",
    "print(f\"   - Precision: {best_anomaly['Precision']:.4f}\")\n",
    "print(f\"   - Recall: {best_anomaly['Recall']:.4f}\")\n",
    "\n",
    "print(\"\\n3. CLASSIFICATION RESULTS\")\n",
    "best_classifier = classification_results_df.loc[classification_results_df['MCC'].idxmax()]\n",
    "print(f\"   Best Model: {best_classifier['Model']}\")\n",
    "print(f\"   - MCC: {best_classifier['MCC']:.4f}\")\n",
    "print(f\"   - Balanced Accuracy: {best_classifier['Balanced Accuracy']:.4f}\")\n",
    "print(f\"   - AUPRC: {best_classifier['AUPRC']:.4f}\")\n",
    "\n",
    "print(\"\\n4. ADVERSARIAL ATTACKS ANALYSIS\")\n",
    "print(f\"   - Baseline accuracy: {baseline_acc:.4f}\")\n",
    "print(f\"   - FGSM is more effective than random noise\")\n",
    "print(f\"   - PGD provides stronger attacks than FGSM\")\n",
    "print(f\"   - Model robustness decreases significantly with epsilon > 0.1\")\n",
    "\n",
    "print(\"\\n5. SECURITY RECOMMENDATIONS\")\n",
    "print(\"   - Implement adversarial training for improved robustness\")\n",
    "print(\"   - Use ensemble methods combining multiple detection approaches\")\n",
    "print(\"   - Regular model retraining with new attack patterns\")\n",
    "print(\"   - Deploy anomaly detection as first defense layer\")\n",
    "print(\"   - Consider input validation and feature monitoring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab01571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV for report\n",
    "anomaly_results_df.to_csv('anomaly_detection_results.csv', index=False)\n",
    "classification_results_df.to_csv('classification_results.csv', index=False)\n",
    "adv_df.to_csv('adversarial_attack_results.csv', index=False)\n",
    "\n",
    "print(\"Results saved to CSV files:\")\n",
    "print(\"  - anomaly_detection_results.csv\")\n",
    "print(\"  - classification_results.csv\")\n",
    "print(\"  - adversarial_attack_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyberml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
